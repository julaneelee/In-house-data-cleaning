{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyObsp8DNUcvAsRLjVjU3lCH",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/julaneelee/In-house-data-cleaning/blob/main/data_cleaning.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üåà1Ô∏è‚É£ **GE invitation email list **"
      ],
      "metadata": {
        "id": "1iq8CQXnMnmR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü©∑ from MRS - author"
      ],
      "metadata": {
        "id": "0naM-EW3o9ow"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import read\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "MRS_author_excel=str(input(\"What is the path of MRS-author excel file in COLAB?: \"))\n",
        "# Load the entire Excel file\n",
        "print(MRS_author_excel)\n",
        "\n",
        "MRS_author_df = pd.read_excel(MRS_author_excel, sheet_name=\"Authors\")\n",
        "# print(MRS_author_df.head())\n",
        "print(MRS_author_df.columns.tolist())\n",
        "print(len(MRS_author_df))\n",
        "# Remove rows where 'EMail' is NaN or blank\n",
        "MRS_author_df = MRS_author_df[MRS_author_df['Email'].notna() & (MRS_author_df['Email'].str.strip() != '')]\n",
        "\n",
        "# Remove duplicate rows based on the 'EMail' column\n",
        "MRS_author_df = MRS_author_df.drop_duplicates(subset='Email', keep='first').reset_index(drop=True)\n",
        "\n",
        "\n",
        "c_author_to_keep = ['Email', 'Country And Region']\n",
        "df_author_column = MRS_author_df[c_author_to_keep]\n",
        "#print(df_author_column.head())\n",
        "print(len(df_author_column))\n",
        "\n",
        "#*************************************************************\n",
        "#I want only Zone1\n",
        "\n",
        "df_author_column.loc[:, 'Country And Region'] = (\n",
        "    df_author_column['Country And Region'].astype(str).str.strip().str.lower()\n",
        ")\n",
        "# List of countries to keep\n",
        "countries_to_keep = [\n",
        "    \"Australia\",\"Austria\",\"Belgium\",\"Bulgaria\",\"Canada\",\"Croatia\",\"Cyprus\",\n",
        "    \"Czech Republic\",\"Denmark\",\"Estonia\",\"Finland\",\"England\",\"Scotland\",\"France\",\"Germany\",\"Greece\",\n",
        "    \"Hungary\",\"Iceland\",\"Ireland\",\"Italy\",\"Japan\",\"Korea\",\"South Korea\",\"Republic of Korea\",\"Latvia\",\n",
        "    \"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\"the Netherlands\",\"New Zealand\",\n",
        "    \"Norway\",\"Poland\",\"Portugal\",\"Romania\",\"Slovakia\",\"Slovenia\",\n",
        "    \"Spain\",\"Sweden\",\"Switzerland\",\"Taiwan\",\"United Kingdom\",\"United States\",\"USA\",\"Usa\",\"UK\",\"Uk\",\n",
        "    \"Hong Kong\",\"Singapore\"\n",
        "]\n",
        "\n",
        "# Convert the list of countries to lowercase\n",
        "countries_to_keep_lower = [c.lower() for c in countries_to_keep]\n",
        "\n",
        "# Filter the dataframe ignoring case\n",
        "df_author_filtered_zone1 = df_author_column[\n",
        "    df_author_column['Country And Region'].isin(countries_to_keep_lower)].reset_index(drop=True)\n",
        "\n",
        "#print(df_author_filtered_zone1.head())\n",
        "#print(len(df_author_filtered_zone1))\n",
        "\n",
        "#*********************************************************************\n",
        "\n",
        "big_domains = [\n",
        "    \"gmail.com\", \"outlook.com\", \"yahoo.com\", \"icloud.com\",\n",
        "    \"hotmail.com\", \"naver.com\", \"windowslive.com\", \"hanmail.com\",\"googlemail.com\",\"samsung.com\",\n",
        "    \"live.com\", \"aol.com\", \"msn.com\", \"mail.com\", \"me.com\", \"mac.com\"\n",
        "]\n",
        "df_author_filtered_zone1 = df_author_filtered_zone1[\n",
        "    ~df_author_filtered_zone1['Email'].str.contains(\"student\", flags=re.IGNORECASE, na=False)\n",
        "].copy()\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á domain ‡∏´‡∏•‡∏±‡∏á @\n",
        "df_author_filtered_zone1['Email_domain'] = df_author_filtered_zone1['Email'].str.split('@').str[-1].str.lower().str.strip()\n",
        "#print(df_filtered_email['Email_domain'] )\n",
        "\n",
        "# big domains + country-specific TLD\n",
        "allowed_domains = big_domains + [\n",
        "    'au','ac', 'at', 'be', 'bg', 'ca', 'hr', 'cy', 'cz', 'dk', 'ee', 'fi', 'fr', 'de', 'gr',\n",
        "    'hu', 'is', 'ie', 'il', 'it', 'jp', 'kr', 'lv', 'li', 'lt', 'lu', 'mt', 'nl', 'nz',\n",
        "    'no', 'pl', 'pt', 'ro', 'sk', 'si', 'es', 'se', 'ch', 'tw', 'uk', 'us', 'hk', 'sg','eu','edu','org','net'\n",
        "]\n",
        "allowed_domains_pattern = \"|\".join([re.escape(d) for d in allowed_domains])\n",
        "\n",
        "df_author_filtered_zone1_default  = df_author_filtered_zone1[\n",
        "    df_author_filtered_zone1['Email_domain'].str.contains(\n",
        "        f\"(?:{allowed_domains_pattern})$\", flags=re.IGNORECASE, na=False\n",
        "    )\n",
        "].reset_index(drop=True)\n",
        "\n",
        "df_author_filtered_zone1_default = df_author_filtered_zone1_default.drop(columns=['Email_domain'])\n",
        "#print(df_author_filtered_zone1_default.head())\n",
        "print(len(df_author_filtered_zone1_default))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Oq__-4zyBj84",
        "outputId": "919ef261-f5e6-4380-a2df-b51cd0f9beb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the path of MRS-author excel file in COLAB?: /content/3.9-author_3b22b8ac91fd5ee28d44221a644519a1.xlsx\n",
            "/content/3.9-author_3b22b8ac91fd5ee28d44221a644519a1.xlsx\n",
            "['Name', 'Last Name', 'Title', 'Email', 'Is correspondence', 'Journal', 'Issue', 'Section', 'SI', 'Msid', 'Title.1', 'Doi', 'Website', 'Susy link', 'Published date', 'Affiliation', 'Country And Region', 'Keywords', 'AE Name', 'AE Email', 'Owner Name', 'Owner Email', 'Author Type', 'Author Type Reason']\n",
            "14569\n",
            "12213\n",
            "9743\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export file - only Author emails\n",
        "\n",
        "Author_email_only = df_author_filtered_zone1_default[\"Email\"].astype(str).str.encode('ascii', 'ignore').str.decode('ascii').str.strip().to_frame()\n",
        "#Author_email_only = pd.DataFrame(Author_email_only, columns=[\"Email\"])\n",
        "#print(Author_email_only)\n",
        "\n",
        "# Ask user for file name\n",
        "Author_email_only_filename = input(\"Enter the name for the Excel file (without extension): \").strip()\n",
        "\n",
        "# Ensure the file name ends with .xlsx\n",
        "if not Author_email_only_filename.endswith(\".xlsx\"):\n",
        "    Author_email_only_filename = Author_email_only_filename + \".xlsx\"\n",
        "\n",
        "# Export file\n",
        "Author_email_only.to_excel(Author_email_only_filename, index=False, engine=\"openpyxl\")\n",
        "print(f\"File saved as: {Author_email_only_filename}\")\n",
        "print(f\"Exported {len(Author_email_only)} rows to {Author_email_only_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S-tN858yGtgy",
        "outputId": "94191bfc-b663-462a-e637-6448736aefa0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name for the Excel file (without extension): 3.9-MRS-author\n",
            "File saved as: 3.9-MRS-author.xlsx\n",
            "Exported 9743 rows to 3.9-MRS-author.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ü©∑ from Scilit"
      ],
      "metadata": {
        "id": "RVtNSJElnGML"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import read\n",
        "import pandas as pd\n",
        "import re\n",
        "\n",
        "Scilit_excel=str(input(\"What is the path of Scilit excel file in COLAB?: \"))\n",
        "# Load the entire Excel file\n",
        "print(Scilit_excel)\n",
        "\n",
        "Scilit_excel_df = pd.read_excel(Scilit_excel, sheet_name=\"Authors\")\n",
        "# print(Scilit_excel_df.head())\n",
        "\n",
        "# Remove rows where 'EMail' is NaN or blank\n",
        "Scilit_excel_df = Scilit_excel_df[Scilit_excel_df['Email'].notna() & (Scilit_excel_df['Email'].str.strip() != '')]\n",
        "# Remove duplicate rows based on the 'EMail' column\n",
        "Scilit_excel_df = Scilit_excel_df.drop_duplicates(subset='Email', keep='first').reset_index(drop=True)\n",
        "\n",
        "print(Scilit_excel_df.columns.tolist())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6bn-nlu4pMrA",
        "outputId": "f15b2c7b-bba3-42de-9353-8cffcbbf03fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the path of Scilit excel file in COLAB?: /content/Crude_export_author_20250821052855_151133.xlsx\n",
            "/content/Crude_export_author_20250821052855_151133.xlsx\n",
            "['Name', 'Affiliation', 'Country/Region', 'Email', 'Author Link', 'H Index', 'Article', 'Article Link', 'Total Citations', 'Published year', 'Journal title', 'Volume', 'First Page', 'Last Page', 'Keywords', 'Abstract']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cs_author_to_keep = ['Email','Country/Region']\n",
        "df_scilit_column = Scilit_excel_df[cs_author_to_keep]\n",
        "#print(df_scilit_column)\n",
        "#print(Scilit_excel_df.head())\n",
        "\n",
        "#*************************************************************\n",
        "#I want only Zone1\n",
        "\n",
        "df_scilit_column.loc[:, 'Country/Region'] = (\n",
        "    df_scilit_column['Country/Region'].astype(str).str.strip().str.lower()\n",
        ")\n",
        "# List of countries to keep\n",
        "countries_to_keep = [\n",
        "    \"Australia\",\"Austria\",\"Belgium\",\"Bulgaria\",\"Canada\",\"Croatia\",\"Cyprus\",\n",
        "    \"Czech Republic\",\"Denmark\",\"Estonia\",\"Finland\",\"England\",\"Scotland\",\"France\",\"Germany\",\"Greece\",\n",
        "    \"Hungary\",\"Iceland\",\"Ireland\",\"Italy\",\"Japan\",\"Korea\",\"South Korea\",\"Republic of Korea\",\"Latvia\",\n",
        "    \"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\"the Netherlands\",\"New Zealand\",\n",
        "    \"Norway\",\"Poland\",\"Portugal\",\"Romania\",\"Slovakia\",\"Slovenia\",\n",
        "    \"Spain\",\"Sweden\",\"Switzerland\",\"Taiwan\",\"United Kingdom\",\"United States\",\"USA\",\"Usa\",\"UK\",\"Uk\",\n",
        "    \"Hong Kong\",\"Singapore\"\n",
        "]\n",
        "\n",
        "# Convert the list of countries to lowercase\n",
        "countries_to_keep_lower = [c.lower() for c in countries_to_keep]\n",
        "\n",
        "# Filter the dataframe ignoring case\n",
        "Scilit_excel_df = df_scilit_column[\n",
        "    df_scilit_column['Country/Region'].isin(countries_to_keep_lower)].reset_index(drop=True)\n",
        "\n",
        "#print(Scilit_excel_df.head())\n",
        "#print(len(Scilit_excel_df))\n",
        "\n",
        "#*********************************************************************\n",
        "\n",
        "big_domains = [\n",
        "    \"gmail.com\", \"outlook.com\", \"yahoo.com\", \"icloud.com\",\n",
        "    \"hotmail.com\", \"naver.com\", \"windowslive.com\", \"hanmail.com\",\"googlemail.com\",\"samsung.com\",\n",
        "    \"live.com\", \"aol.com\", \"msn.com\", \"mail.com\", \"me.com\", \"mac.com\"\n",
        "]\n",
        "Scilit_excel_df = Scilit_excel_df[\n",
        "    ~Scilit_excel_df['Email'].str.contains(\"student\", flags=re.IGNORECASE, na=False)\n",
        "].copy()\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á domain ‡∏´‡∏•‡∏±‡∏á @\n",
        "Scilit_excel_df['Email_domain'] = Scilit_excel_df['Email'].str.split('@').str[-1].str.lower().str.strip()\n",
        "#print(df_filtered_email['Email_domain'] )\n",
        "\n",
        "# big domains + country-specific TLD\n",
        "allowed_domains = big_domains + [\n",
        "    'au','ac', 'at', 'be', 'bg', 'ca', 'hr', 'cy', 'cz', 'dk', 'ee', 'fi', 'fr', 'de', 'gr',\n",
        "    'hu', 'is', 'ie', 'il', 'it', 'jp', 'kr', 'lv', 'li', 'lt', 'lu', 'mt', 'nl', 'nz',\n",
        "    'no', 'pl', 'pt', 'ro', 'sk', 'si', 'es', 'se', 'ch', 'tw', 'uk', 'us', 'hk', 'sg','eu','edu','org','net'\n",
        "]\n",
        "allowed_domains_pattern = \"|\".join([re.escape(d) for d in allowed_domains])\n",
        "\n",
        "Scilit_excel_df_default  = Scilit_excel_df[\n",
        "    Scilit_excel_df['Email_domain'].str.contains(\n",
        "        f\"(?:{allowed_domains_pattern})$\", flags=re.IGNORECASE, na=False\n",
        "    )\n",
        "].reset_index(drop=True)\n",
        "\n",
        "Scilit_excel_df_default = Scilit_excel_df_default.drop(columns=['Email_domain'])\n",
        "print(Scilit_excel_df_default.head())\n",
        "print(len(Scilit_excel_df_default))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gA7A2onUoyEb",
        "outputId": "3ea0f616-027f-4d94-83c4-e09783a8c37c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                     Email Country/Region\n",
            "0  asingh@southalabama.edu  united states\n",
            "1       rmitra@roseman.edu  united states\n",
            "2       zmgpg123@knu.ac.kr    south korea\n",
            "3      krhasan02@knu.ac.kr    south korea\n",
            "4         yuando@knu.ac.kr    south korea\n",
            "35130\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Export file - only Author emails\n",
        "\n",
        "scilit_email_only = Scilit_excel_df_default[\"Email\"].astype(str).str.encode('ascii', 'ignore').str.decode('ascii').str.strip().to_frame()\n",
        "#scilit_email_only = pd.DataFrame(scilit_email_only, columns=[\"Email\"])\n",
        "#print(scilit_email_only)\n",
        "\n",
        "# Ask user for file name\n",
        "scilit_email_only_filename = input(\"Enter the name for the Excel file (without extension): \").strip()\n",
        "\n",
        "# Ensure the file name ends with .xlsx\n",
        "if not scilit_email_only_filename.endswith(\".xlsx\"):\n",
        "   scilit_email_only_filename = scilit_email_only_filename + \".xlsx\"\n",
        "\n",
        "# Export file\n",
        "scilit_email_only.to_excel(scilit_email_only_filename, index=False, engine=\"openpyxl\")\n",
        "print(f\"File saved as: {scilit_email_only_filename}\")\n",
        "print(f\"Exported {len(scilit_email_only)} rows to {scilit_email_only_filename}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hhGkfLyOo3yC",
        "outputId": "f8b866cd-a75d-4ecd-b11a-a02a4a4e672b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name for the Excel file (without extension): scilit-email\n",
            "File saved as: scilit-email.xlsx\n",
            "Exported 35130 rows to scilit-email.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## from Web of Science"
      ],
      "metadata": {
        "id": "JmB7I-FPkUbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from google.colab import files\n",
        "\n",
        "# Step 1: Ask user to upload file\n",
        "print(\"üìÇ Please upload your Excel file:\")\n",
        "uploaded = files.upload()\n",
        "\n",
        "# Get the uploaded file name (first key in dict)\n",
        "file_name = list(uploaded.keys())[0]\n",
        "\n",
        "# Step 2: Read only 'EM' column\n",
        "df = pd.read_excel(file_name, usecols=[\"EM\"])\n",
        "\n",
        "# Step 3: Split emails by semicolon and explode\n",
        "df_clean = df['EM'].str.split(r'\\s*;\\s*').explode().reset_index(drop=True)\n",
        "\n",
        "# Step 4: Put into DataFrame\n",
        "df_clean = pd.DataFrame(df_clean, columns=[\"EM\"])\n",
        "\n",
        "\n",
        "# Step 5: Remove blanks/NaN + duplicates\n",
        "df_clean = df_clean[df_clean['EM'].notna() & (df_clean['EM'].str.strip() != \"\")]\n",
        "df_clean = df_clean.drop_duplicates().reset_index(drop=True)\n",
        "\n",
        "\n",
        "# Step 6: Save cleaned file\n",
        "output_file = \"emails_cleaned.xlsx\"\n",
        "df_clean.to_excel(output_file, index=False)\n",
        "\n",
        "# Step 7: Download the file\n",
        "files.download(output_file)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "id": "AVuiY0QWkTwn",
        "outputId": "7c0d3a9e-c472-4dc7-8543-3abee5e61747"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üìÇ Please upload your Excel file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-2a1cd91e-cf3f-412e-8769-9bafdab92b2c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-2a1cd91e-cf3f-412e-8769-9bafdab92b2c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving crude&1.xlsx to crude&1.xlsx\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_195508b3-8659-4c0f-b71a-080f2b7a4ace\", \"emails_cleaned.xlsx\", 459675)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## üíõAfter we get the file for export and upload to MRS-Editor-invited/SCILIT to get H-index, after get the file from MRS then REUPLOAD/IMPORT FILE TO HERE AGAIN!!!!"
      ],
      "metadata": {
        "id": "aegeG1C1TFWB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MRS_editor_excel=str(input(\"What is the path of MRS-EDITOR excel file in COLAB?: \"))\n",
        "# Load the entire Excel file\n",
        "print(MRS_editor_excel)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yvOeQM0CcUqx",
        "outputId": "e3ac4141-15e0-4dff-82f6-f15e9ce76a21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the path of MRS-EDITOR excel file in COLAB?: /content/3.9-MRS_Data_Editor_Invited_1756861932.xlsx\n",
            "/content/3.9-MRS_Data_Editor_Invited_1756861932.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "MRS_editor_df = pd.read_excel(MRS_editor_excel, sheet_name=\"Sheet1\")\n",
        "\n",
        "# Remove rows where 'EMail' is NaN or blank\n",
        "MRS_editor_df = MRS_editor_df[MRS_editor_df['Email'].notna() & (MRS_editor_df['Email'].str.strip() != '')]\n",
        "# Remove duplicate rows based on the 'EMail' column\n",
        "MRS_editor_df = MRS_editor_df.drop_duplicates(subset='Email', keep='first').reset_index(drop=True)\n",
        "\n",
        "# Columns to check\n",
        "cols_to_check_block = ['Block from editing Special Issue/Topic Collection as Guest Editor',\n",
        "                       'Block from receiving CfPs and similar emails',\n",
        "                       'Block from reviewing manuscripts',\n",
        "                       'Automated blacklist for CFP',\n",
        "                       'Block from newsletters and cooperate informations',\n",
        "                       'Block from receiving participation emails from Sciforum',\n",
        "                       'Block from being Topical Advisory Panel/Editorial Board Member',\n",
        "                       'Block from receiving employee recruit emails',\n",
        "                       'Receive MDPI Books Mailing'\n",
        "]\n",
        "\n",
        "# Keep only rows where none of the columns contain \"Yes\"\n",
        "MRS_editor_df_filtered = MRS_editor_df[~MRS_editor_df[cols_to_check_block].apply(lambda row: row.str.contains(\"Yes\", case=False, na=False)).any(axis=1)]\n",
        "MRS_editor_df_filtered = MRS_editor_df_filtered.drop(columns= cols_to_check_block)\n",
        "#print(MRS_editor_df_filtered.head())\n",
        "status_GE = [\"Guest Editor - Invited\",\n",
        "             \"Guest Editor - Uninvited\",\n",
        "             \"Guest Editor - Rejected\",\n",
        "             \"Topic Editor - Invited\",\n",
        "             \"Section Board Member - Invited\",\n",
        "             \"Section Board Member - Uninvited\",\n",
        "             \"Section Board Member - Rejected\",\n",
        "             \"Editorial Board Member - Invited\",\n",
        "             \"Editorial Board Member - Uninvited\",\n",
        "             \"Editorial Board Member - Rejected\",\n",
        "             \"RB-Invited\",\n",
        "             \"RB-Uninvited\",\n",
        "             \"RB-Rejected\",\n",
        "             \"Topical Advisory Panel Member - Invited\",\n",
        "             \"Topical Advisory Panel Member - Uninvited\",\n",
        "             \"Topical Advisory Panel Member - Rejected\",\"\",\" \"\n",
        "]\n",
        "\n",
        "# Keep only rows where column Status is in the list\n",
        "# Keep only rows where column Status is in the list OR blank\n",
        "MRS_editor_df_filtered = MRS_editor_df_filtered[\n",
        "    MRS_editor_df_filtered['Status'].isin(status_GE) |\n",
        "    (MRS_editor_df_filtered['Status'].isna()) |\n",
        "    (MRS_editor_df_filtered['Status'].str.strip() == '')\n",
        "]\n",
        "\n",
        "#print(MRS_editor_df_filtered.columns.to_list())\n",
        "MRS_editor_df_filtered = MRS_editor_df_filtered[['Email', 'Name', 'H-index', 'Invited Date', 'Status', 'Invited Numbers']]\n",
        "print(MRS_editor_df_filtered.head())\n",
        "print(len(MRS_editor_df_filtered))\n"
      ],
      "metadata": {
        "id": "BXPyhwZfTivB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fa17d384-1d0f-4ec1-c77f-7a644f49e5a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "                               Email                 Name H-index  \\\n",
            "1  jan.kuehnisch@med.uni-muenchen.de         Jan K√ºhnisch      26   \n",
            "2                 takakura@tau.ac.jp     Nobuari Takakura      12   \n",
            "3       antonello.rigamonti@unimi.it  Antonello Rigamonti      25   \n",
            "6        marinescu_roxanna@yahoo.com     Roxana Marinescu       4   \n",
            "7            migliorini.md@gmail.com   Filippo Migliorini      19   \n",
            "\n",
            "          Invited Date                   Status  Invited Numbers  \n",
            "1  2024-05-13 10:11:11   Guest Editor - Invited               16  \n",
            "2  2025-07-17 11:08:42  Guest Editor - Rejected               13  \n",
            "3  2025-06-14 18:25:10   Guest Editor - Invited               22  \n",
            "6                  NaN                      NaN                0  \n",
            "7  2025-08-28 04:20:53   Guest Editor - Invited               21  \n",
            "6651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Ensure Invited Date is datetime type\n",
        "MRS_editor_df_filtered['Invited Date'] = pd.to_datetime(MRS_editor_df_filtered['Invited Date'], errors='coerce')\n",
        "\n",
        "# 1. Create new column with +90 days and +5 hours\n",
        "MRS_editor_df_filtered['Available Date (+90d5hrs)'] = (\n",
        "    MRS_editor_df_filtered['Invited Date'] + pd.Timedelta(days=90, hours=5)\n",
        ")\n",
        "\n",
        "# 2. Ask user for H-index range\n",
        "min_h = float(input(\"Enter minimum H-index to keep: \"))\n",
        "max_h = float(input(\"Enter maximum H-index to keep: \"))\n",
        "\n",
        "# Convert H-index to numeric, remove non-numeric or blank\n",
        "MRS_editor_df_filtered['H-index'] = pd.to_numeric(MRS_editor_df_filtered['H-index'], errors='coerce')\n",
        "\n",
        "# Filter H-index dynamically\n",
        "MRS_editor_df_filtered = MRS_editor_df_filtered[\n",
        "    (MRS_editor_df_filtered['H-index'] >= min_h) &\n",
        "    (MRS_editor_df_filtered['H-index'] <= max_h)\n",
        "]\n",
        "\n",
        "# 3. Ask user for max Invited Numbers\n",
        "max_invited = float(input(\"Enter maximum Invited Numbers to keep (blank counted as 0): \"))\n",
        "\n",
        "# Convert Invited Numbers to numeric, fill blank/NaN with 0\n",
        "MRS_editor_df_filtered['Invited Numbers'] = pd.to_numeric(MRS_editor_df_filtered['Invited Numbers'], errors='coerce').fillna(0)\n",
        "\n",
        "# Filter Invited Numbers dynamically\n",
        "MRS_editor_df_filtered = MRS_editor_df_filtered[MRS_editor_df_filtered['Invited Numbers'] <= max_invited]\n",
        "\n",
        "\n",
        "\n",
        "# Show result\n",
        "print(MRS_editor_df_filtered.head())\n",
        "print(len(MRS_editor_df_filtered))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zgo1uGsHeJPu",
        "outputId": "70bea8cd-15fc-4de3-921b-45473fcbe102"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter minimum H-index to keep: 10\n",
            "Enter maximum H-index to keep: 30\n",
            "Enter maximum Invited Numbers to keep (blank counted as 0): 5\n",
            "                               Email                     Name  H-index  \\\n",
            "24                flassner@gmail.com            Franz Lassner     15.0   \n",
            "54   apocobelli@hsangiovanni.roma.it        Augusto Pocobelli     11.0   \n",
            "77             simina.crisan@umft.ro            Simina Crisan     10.0   \n",
            "181            b1208b@ms26.hinet.net             Pei Yuan Lee     15.0   \n",
            "182             j_blumenstein@gmx.de  Johannes M. Blumenstein     26.0   \n",
            "\n",
            "           Invited Date                    Status  Invited Numbers  \\\n",
            "24  2025-07-21 03:53:03    Guest Editor - Invited                4   \n",
            "54  2025-06-23 10:13:38  Guest Editor - Uninvited                4   \n",
            "77  2025-06-09 09:36:53    Guest Editor - Invited                2   \n",
            "181 2025-06-04 09:43:57    Guest Editor - Invited                4   \n",
            "182 2025-07-21 05:25:16    Guest Editor - Invited                5   \n",
            "\n",
            "    Available Date (+90d5hrs)  \n",
            "24        2025-10-19 08:53:03  \n",
            "54        2025-09-21 15:13:38  \n",
            "77        2025-09-07 14:36:53  \n",
            "181       2025-09-02 14:43:57  \n",
            "182       2025-10-19 10:25:16  \n",
            "472\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#Ask user for cutoff date (DD.MM.YYYY) and filter Invited Date Plus 90d5h\n",
        "user_date_input = input(\"Enter cutoff date (DD.MM.YYYY): \")\n",
        "cutoff_date = pd.to_datetime(user_date_input, format=\"%d.%m.%Y\")\n",
        "\n",
        "# Extend cutoff to end of day (23:59:59.999999)\n",
        "cutoff_date = cutoff_date + pd.Timedelta(days=1) - pd.Timedelta(microseconds=1)\n",
        "\n",
        "# Keep only rows where Invited Date Plus 90d5h is before or equal to cutoff\n",
        "new_filtered_df_invite = MRS_editor_df_filtered[\n",
        "    (MRS_editor_df_filtered['Available Date (+90d5hrs)'] <= cutoff_date) |\n",
        "    (MRS_editor_df_filtered['Available Date (+90d5hrs)'].isna())\n",
        "].copy()\n",
        "\n",
        "\n",
        "# Display result\n",
        "print(new_filtered_df_invite)\n",
        "print(\"Total rows after all filtering:\", len(new_filtered_df_invite))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qC_5X4azg161",
        "outputId": "da7193be-8e67-4f14-cf6b-0144673858b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter cutoff date (DD.MM.YYYY): 3.9.2025\n",
            "                                      Email                 Name  H-index  \\\n",
            "181                   b1208b@ms26.hinet.net         Pei Yuan Lee     15.0   \n",
            "621               saad.alhumaid@utas.edu.au        Saad Alhumaid     26.0   \n",
            "927          rana.garayzade@med.uni-jena.de      Rana  Garayzade     11.0   \n",
            "950         frederic.chagnon@usherbrooke.ca     Fr√©d√©ric Chagnon     12.0   \n",
            "1100                     dlwheeler@wisc.edu        Deric Wheeler     28.0   \n",
            "...                                     ...                  ...      ...   \n",
            "9578            alessandr.cartocci@unisi.it  Alessandra Cartocci     15.0   \n",
            "9581         ulrich.zissler@th-rosenheim.de        Ulrich Zi√üler     21.0   \n",
            "9644                 wldmsrla80@hanmail.net           Ji Eun Kim     11.0   \n",
            "9685                   hribeiroff@gmail.com         Hugo Ribeiro     12.0   \n",
            "9719  pierluigi.russo@policlinicogemelli.it      Pierluigi Russo     20.0   \n",
            "\n",
            "                                Status  Invited Numbers  \\\n",
            "181             Guest Editor - Invited                4   \n",
            "621   Section Board Member - Uninvited                2   \n",
            "927             Guest Editor - Invited                1   \n",
            "950           Guest Editor - Uninvited                5   \n",
            "1100            Guest Editor - Invited                5   \n",
            "...                                ...              ...   \n",
            "9578            Guest Editor - Invited                1   \n",
            "9581            Guest Editor - Invited                3   \n",
            "9644                               NaN                0   \n",
            "9685                               NaN                0   \n",
            "9719            Guest Editor - Invited                2   \n",
            "\n",
            "     Available Date (+90d5hrs)  \n",
            "181        2025-09-02 14:43:57  \n",
            "621        2025-07-10 16:49:18  \n",
            "927        2025-01-22 16:12:37  \n",
            "950        2025-09-03 13:46:00  \n",
            "1100       2022-02-22 09:30:26  \n",
            "...                        ...  \n",
            "9578       2025-08-06 10:03:40  \n",
            "9581       2025-09-01 15:42:35  \n",
            "9644                       NaT  \n",
            "9685                       NaT  \n",
            "9719       2025-09-02 10:29:43  \n",
            "\n",
            "[69 rows x 6 columns]\n",
            "Total rows after all filtering: 69\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Ask user for file name\n",
        "GE_invite_filename = input(\"Enter the name for GE invitation file (without extension): \").strip()\n",
        "\n",
        "# Ensure the file name ends with .xlsx\n",
        "if not GE_invite_filename.endswith(\".xlsx\"):\n",
        "    GE_invite_filename = GE_invite_filename + \".xlsx\"\n",
        "\n",
        "\n",
        "#print(new_filtered_df_invite)\n",
        "# Export file\n",
        "new_filtered_df_invite.to_excel(GE_invite_filename, index=False, engine=\"openpyxl\")\n",
        "print(f\"File saved as: {GE_invite_filename}\")\n",
        "print(f\"Exported {len(new_filtered_df_invite)} rows to {GE_invite_filename}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rCbAvPxxh1MJ",
        "outputId": "1a11b7a9-a96a-4a2d-dd14-af5243c94c2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name for GE invitation file (without extension): 111\n",
            "                                      Email                 Name  H-index  \\\n",
            "181                   b1208b@ms26.hinet.net         Pei Yuan Lee     15.0   \n",
            "621               saad.alhumaid@utas.edu.au        Saad Alhumaid     26.0   \n",
            "927          rana.garayzade@med.uni-jena.de      Rana  Garayzade     11.0   \n",
            "950         frederic.chagnon@usherbrooke.ca     Fr√©d√©ric Chagnon     12.0   \n",
            "1100                     dlwheeler@wisc.edu        Deric Wheeler     28.0   \n",
            "...                                     ...                  ...      ...   \n",
            "9578            alessandr.cartocci@unisi.it  Alessandra Cartocci     15.0   \n",
            "9581         ulrich.zissler@th-rosenheim.de        Ulrich Zi√üler     21.0   \n",
            "9644                 wldmsrla80@hanmail.net           Ji Eun Kim     11.0   \n",
            "9685                   hribeiroff@gmail.com         Hugo Ribeiro     12.0   \n",
            "9719  pierluigi.russo@policlinicogemelli.it      Pierluigi Russo     20.0   \n",
            "\n",
            "                                Status  Invited Numbers  \\\n",
            "181             Guest Editor - Invited                4   \n",
            "621   Section Board Member - Uninvited                2   \n",
            "927             Guest Editor - Invited                1   \n",
            "950           Guest Editor - Uninvited                5   \n",
            "1100            Guest Editor - Invited                5   \n",
            "...                                ...              ...   \n",
            "9578            Guest Editor - Invited                1   \n",
            "9581            Guest Editor - Invited                3   \n",
            "9644                               NaN                0   \n",
            "9685                               NaN                0   \n",
            "9719            Guest Editor - Invited                2   \n",
            "\n",
            "     Available Date (+90d5hrs)  \n",
            "181        2025-09-02 14:43:57  \n",
            "621        2025-07-10 16:49:18  \n",
            "927        2025-01-22 16:12:37  \n",
            "950        2025-09-03 13:46:00  \n",
            "1100       2022-02-22 09:30:26  \n",
            "...                        ...  \n",
            "9578       2025-08-06 10:03:40  \n",
            "9581       2025-09-01 15:42:35  \n",
            "9644                       NaT  \n",
            "9685                       NaT  \n",
            "9719       2025-09-02 10:29:43  \n",
            "\n",
            "[69 rows x 6 columns]\n",
            "File saved as: 111.xlsx\n",
            "Exported 69 rows to 111.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#üåà2Ô∏è‚É£ **CFP- Email Invitation Preparation** from Purged - MDPI backend"
      ],
      "metadata": {
        "id": "0lmorP586LqR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1) Filter Email and country"
      ],
      "metadata": {
        "id": "PbNAsXLWm4W0"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Import file we get from MDPI backend (Scilit request) or call \"Purged email\" >> Manually merge 'notMatch' sheet to 'purged' sheet (remove grey highlight, keep green, blue, yellow) >> file contains only one sheet name 'purged' >> Save as new file >> UPLOAD TO COLAB >> Fill in the PATH IN CODE >> RUN"
      ],
      "metadata": {
        "id": "BsUVlbfI-0L-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from os import read\n",
        "import pandas as pd\n",
        "\n",
        "excel_file=str(input(\"What is the path of file in COLAB?: \"))\n",
        "# Load the entire Excel file\n",
        "print(excel_file)"
      ],
      "metadata": {
        "id": "39aOEU-dBfzt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "988b70d9-1c7c-417a-9d21-77435ce43e20"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "What is the path of file in COLAB?: /content/2.9-scilit-CFP.xlsx\n",
            "/content/2.9-scilit-CFP.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "1GJP5JA9tDpN",
        "outputId": "26a96ebc-f5bf-4b61-d502-988d62ca9f74"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Name', 'EMail', 'Reference', 'Link', 'Google Scholar', 'TC', 'PY', 'Affiliation', 'Check', 'Country/Region', 'Publisher', 'Voucher amount', 'Central pay', 'Discount percent', 'Unnamed: 14']\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Option 1: Read all sheets into a dictionary of DataFrames\n",
        "df = pd.read_excel(excel_file, sheet_name=\"purged\") #sheet_name=None ‡∏Ñ‡∏∑‡∏≠‡∏≠‡πà‡∏≤‡∏ô‡∏ó‡∏±‡πâ‡∏á‡∏´‡∏°‡∏î‡∏ó‡∏∏‡∏Å‡∏ä‡∏µ‡∏ï\n",
        "\n",
        "# Print the sheet names\n",
        "#print(df.head())  #df.key() = List all sheet names in Excel file,\n",
        "print(df.columns.tolist()) # df.columns.tolist() = Get column name in list"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "columns_to_keep = ['Name', 'EMail', 'Reference', 'Affiliation', 'Country/Region']\n",
        "df_filtered_column = df[columns_to_keep]\n",
        "\n",
        "# Remove rows where 'EMail' is NaN or blank\n",
        "df_filtered_column = df_filtered_column[df_filtered_column['EMail'].notna() & (df_filtered_column['EMail'].str.strip() != '')]\n",
        "\n",
        "# Remove duplicate rows based on the 'EMail' column\n",
        "df_filtered_column = df_filtered_column.drop_duplicates(subset='EMail', keep='first').reset_index(drop=True)\n",
        "\n",
        "# df_filtered_column now has only unique, non-empty emails\n",
        "\n",
        "# Display the result\n",
        "print(df_filtered_column.head())\n",
        "print(len(df_filtered_column))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "TpiY565Wu-WA",
        "outputId": "5dbaad99-71f7-41ed-b833-892c5996a72e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "         Name                            EMail  \\\n",
            "0      Siomou                eva21sm@gmail.com   \n",
            "1    Witschey  witschey@pennmedicine.upenn.edu   \n",
            "2       Suhas          suhas.mathavu@gmail.com   \n",
            "3       ≈ûenol        ebrusenol18@ogr.iu.edu.tr   \n",
            "4  Elkhalladi       jaouadelkhalladi@gmail.com   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Patient Dose Estimation in Computed Tomography...   \n",
            "1  Strategies for Implementing Machine Learning A...   \n",
            "2  Enhancing Precision in Medical Imaging: A 3D C...   \n",
            "3  Should Breastfeeding Be Interrupted after Radi...   \n",
            "4  The Impact of the Flipped Classroom on the Dev...   \n",
            "\n",
            "                                         Affiliation Country/Region  \n",
            "0                        Evagellia Siomou (author),             NaN  \n",
            "1  Walter R. Witschey (author), Department of Rad...            USA  \n",
            "2  M. V. Suhas (author), Department of Electronic...          India  \n",
            "3  Ebru ≈ûenol (author), Social Pediatrics Doctora...         Turkey  \n",
            "4  Jaouad Elkhalladi (author), Faculty of Medicin...        Morocco  \n",
            "19721\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#I want only Zone1\n",
        "\n",
        "df_filtered_column.loc[:, 'Country/Region'] = (\n",
        "    df_filtered_column['Country/Region'].astype(str).str.strip().str.lower()\n",
        ")\n",
        "\n",
        "# List of countries to keep\n",
        "countries_to_keep = [\n",
        "    \"Australia\",\"Austria\",\"Belgium\",\"Bulgaria\",\"Canada\",\"Croatia\",\"Cyprus\",\n",
        "    \"Czech Republic\",\"Denmark\",\"Estonia\",\"Finland\",\"England\",\"Scotland\",\"France\",\"Germany\",\"Greece\",\n",
        "    \"Hungary\",\"Iceland\",\"Ireland\",\"Italy\",\"Japan\",\"Korea\",\"South Korea\",\"Republic of Korea\",\"Latvia\",\n",
        "    \"Liechtenstein\",\"Lithuania\",\"Luxembourg\",\"Malta\",\"Netherlands\",\"the Netherlands\",\"New Zealand\",\n",
        "    \"Norway\",\"Poland\",\"Portugal\",\"Romania\",\"Slovakia\",\"Slovenia\",\n",
        "    \"Spain\",\"Sweden\",\"Switzerland\",\"Taiwan\",\"United Kingdom\",\"United States\",\"USA\",\"Usa\",\"UK\",\"Uk\",\n",
        "    \"Hong Kong\",\"Singapore\"\n",
        "]\n",
        "\n",
        "# Convert the list of countries to lowercase\n",
        "countries_to_keep_lower = [c.lower() for c in countries_to_keep]\n",
        "\n",
        "# Filter the dataframe ignoring case\n",
        "df_filtered_zone1 = df_filtered_column[\n",
        "    df_filtered_column['Country/Region'].isin(countries_to_keep_lower)].reset_index(drop=True)\n",
        "\n",
        "print(df_filtered_zone1.head())\n",
        "print(len(df_filtered_zone1))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "83WMTTa_ykhh",
        "outputId": "14d851c9-aba8-4354-8c48-5adf857acf48",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name                            EMail  \\\n",
            "0  Witschey  witschey@pennmedicine.upenn.edu   \n",
            "1  Al Sayed          assemalsayed9@gmail.com   \n",
            "2    Kaseda      ryoheik@med.niigata-u.ac.jp   \n",
            "3      Rusu   mihageorgeta@elearn.umfcluj.ro   \n",
            "4       Oda           moda@is.nagoya-u.ac.jp   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  Radiological examination of greater palatine c...   \n",
            "2  Sodium Magnetic Resonance Imaging Shows Impair...   \n",
            "3  The Role of an MRI-Based Radiomic Signature in...   \n",
            "4  Automated Detection and Diagnosis of Spinal Sc...   \n",
            "\n",
            "                                         Affiliation Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...            usa  \n",
            "1  Assem Al Sayed (author), College of Osteopathi...            usa  \n",
            "2  Ryohei Kaseda (author), Division of Clinical N...          japan  \n",
            "3  Georgeta Mihaela Rusu (author), Department of ...        romania  \n",
            "4  Masahiro Oda (author), Information Strategy Of...          japan  \n",
            "10081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# I want to remove company affiliation, and thoese non-related affiliation to clinical medicine\n",
        "\n",
        "import re\n",
        "# ‡∏•‡∏ö‡∏Ñ‡∏≥‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö company + animal + agriculture\n",
        "pattern = r'\\b(?:inc|ltd|animal|veterinary|agricult|agriculture|agricultural)\\b'\n",
        "\n",
        "df_filtered_affiliation = df_filtered_zone1[\n",
        "    ~df_filtered_zone1['Affiliation'].str.contains(pattern, flags=re.IGNORECASE, na=False)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "print(df_filtered_affiliation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4WwRQV5__ua",
        "outputId": "22238f97-1d3c-4912-e4bf-8dcde07363da",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           Name                            EMail  \\\n",
            "0      Witschey  witschey@pennmedicine.upenn.edu   \n",
            "1      Al Sayed          assemalsayed9@gmail.com   \n",
            "2        Kaseda      ryoheik@med.niigata-u.ac.jp   \n",
            "3          Rusu   mihageorgeta@elearn.umfcluj.ro   \n",
            "4           Oda           moda@is.nagoya-u.ac.jp   \n",
            "...         ...                              ...   \n",
            "9981  Duimering           adele.duimering@ahs.ca   \n",
            "9982      Nakao              naktazdim@gmail.com   \n",
            "9983    Takatsu    yasuo.takatsu@fujita-hu.ac.jp   \n",
            "9984   Hemphill        scotthemphill94@gmail.com   \n",
            "9985     Conway                     sjc@jhmi.edu   \n",
            "\n",
            "                                              Reference  \\\n",
            "0     Strategies for Implementing Machine Learning A...   \n",
            "1     Radiological examination of greater palatine c...   \n",
            "2     Sodium Magnetic Resonance Imaging Shows Impair...   \n",
            "3     The Role of an MRI-Based Radiomic Signature in...   \n",
            "4     Automated Detection and Diagnosis of Spinal Sc...   \n",
            "...                                                 ...   \n",
            "9981  Utility of Chatbot Literature Search in Radiat...   \n",
            "9982  Using Segment Anything Model 2 for Zero-Shot 3...   \n",
            "9983  Optimization of three-dimensional T2-weighted ...   \n",
            "9984  The implementation of artificial intelligence ...   \n",
            "9985  Refocusing the Lens: Adding Downstream Value t...   \n",
            "\n",
            "                                            Affiliation Country/Region  \n",
            "0     Walter R. Witschey (author), Department of Rad...            usa  \n",
            "1     Assem Al Sayed (author), College of Osteopathi...            usa  \n",
            "2     Ryohei Kaseda (author), Division of Clinical N...          japan  \n",
            "3     Georgeta Mihaela Rusu (author), Department of ...        romania  \n",
            "4     Masahiro Oda (author), Information Strategy Of...          japan  \n",
            "...                                                 ...            ...  \n",
            "9981  Adele Duimering (author), Division of Radiatio...         canada  \n",
            "9982  Takahiro Nakao (author), Department of Computa...          japan  \n",
            "9983  Yasuo Takatsu (author), Major in Medical Scien...          japan  \n",
            "9984  Scott Hemphill (author), ASir Charles Gairdner...      australia  \n",
            "9985  Sarah J. Conway (author), Johns Hopkins Clin A...            usa  \n",
            "\n",
            "[9986 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import re\n",
        "\n",
        "big_domains = [\n",
        "    \"gmail.com\", \"outlook.com\", \"yahoo.com\", \"icloud.com\",\n",
        "    \"hotmail.com\", \"naver.com\", \"windowslive.com\", \"hanmail.com\",\"googlemail.com\",\"samsung.com\",\n",
        "    \"live.com\", \"aol.com\", \"msn.com\", \"mail.com\", \"me.com\", \"mac.com\"\n",
        "]\n",
        "\n",
        "df_filtered_email = df_filtered_affiliation[\n",
        "    ~df_filtered_affiliation['EMail'].str.contains(\"student\", flags=re.IGNORECASE, na=False)\n",
        "].copy()\n",
        "\n",
        "# ‡∏î‡∏∂‡∏á domain ‡∏´‡∏•‡∏±‡∏á @\n",
        "df_filtered_email['Email_domain'] = df_filtered_email['EMail'].str.split('@').str[-1].str.lower().str.strip()\n",
        "#print(df_filtered_email['Email_domain'] )\n",
        "\n",
        "# big domains + country-specific TLD\n",
        "allowed_domains = big_domains + [\n",
        "    'au','ac', 'at', 'be', 'bg', 'ca', 'hr', 'cy', 'cz', 'dk', 'ee', 'fi', 'fr', 'de', 'gr',\n",
        "    'hu', 'is', 'ie', 'il', 'it', 'jp', 'kr', 'lv', 'li', 'lt', 'lu', 'mt', 'nl', 'nz',\n",
        "    'no', 'pl', 'pt', 'ro', 'sk', 'si', 'es', 'se', 'ch', 'tw', 'uk', 'us', 'hk', 'sg','eu','edu','org','net'\n",
        "]\n",
        "allowed_domains_pattern = \"|\".join([re.escape(d) for d in allowed_domains])\n",
        "\n",
        "df_default  = df_filtered_email[\n",
        "    df_filtered_email['Email_domain'].str.contains(\n",
        "        f\"(?:{allowed_domains_pattern})$\", flags=re.IGNORECASE, na=False\n",
        "    )\n",
        "].reset_index(drop=True)\n",
        "\n",
        "df_default = df_default.drop(columns=['Email_domain'])\n"
      ],
      "metadata": {
        "collapsed": true,
        "id": "ZWAQWpWLChcf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_default.head())\n",
        "print(len(df_default ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "D3_XpBL-IpJr",
        "outputId": "9fdd50ac-712c-4052-f8e1-a8e9230c19c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name                            EMail  \\\n",
            "0  Witschey  witschey@pennmedicine.upenn.edu   \n",
            "1  Al Sayed          assemalsayed9@gmail.com   \n",
            "2    Kaseda      ryoheik@med.niigata-u.ac.jp   \n",
            "3      Rusu   mihageorgeta@elearn.umfcluj.ro   \n",
            "4       Oda           moda@is.nagoya-u.ac.jp   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  Radiological examination of greater palatine c...   \n",
            "2  Sodium Magnetic Resonance Imaging Shows Impair...   \n",
            "3  The Role of an MRI-Based Radiomic Signature in...   \n",
            "4  Automated Detection and Diagnosis of Spinal Sc...   \n",
            "\n",
            "                                         Affiliation Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...            usa  \n",
            "1  Assem Al Sayed (author), College of Osteopathi...            usa  \n",
            "2  Ryohei Kaseda (author), Division of Clinical N...          japan  \n",
            "3  Georgeta Mihaela Rusu (author), Department of ...        romania  \n",
            "4  Masahiro Oda (author), Information Strategy Of...          japan  \n",
            "9651\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ùó(optional) Generate default file: filtered only Zone1 email + not company or not related to field outside medical scope"
      ],
      "metadata": {
        "id": "7hjdjUDxJF3q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#In case you want simple filtered file (filtered only Zone1 email + not company or related to field outside medical scope)\n",
        "\n",
        "output_file_default = \"filtered_email_default.xlsx\"\n",
        "\n",
        "# Export ‡πÄ‡∏õ‡πá‡∏ô Excel\n",
        "df_default.to_excel(output_file_default, index=False)\n",
        "\n",
        "print(f\"Exported {len(df_default)} rows to {output_file_default}\")"
      ],
      "metadata": {
        "id": "Clnb7KS8Encn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b38422f-6136-4d43-9985-6a756be83486"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported 2784 rows to filtered_email_default.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ù§ 2) **Affilitation column filtering** #‡πÄ‡∏≠‡∏≤‡πÅ‡∏Ñ‡πà Email ‡∏ó‡∏µ‡πà‡∏°‡∏µ‡∏ä‡∏∑‡πà‡∏≠ affiliation ‡∏ï‡∏£‡∏á‡∏Å‡∏±‡∏ö‡∏Ñ‡∏≥‡πÄ‡∏â‡∏û‡∏≤‡∏∞"
      ],
      "metadata": {
        "id": "lp6CBY1J65AF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏£‡∏±‡∏ö input keyword ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma)\n",
        "user_input = input(\"‡∏Å‡∏£‡∏≠‡∏Å keyword ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Affiliation (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma): \")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Cwnwijo9KBYz",
        "outputId": "337bc6f5-ffec-41f9-a66d-6d030feec545"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡∏Å‡∏£‡∏≠‡∏Å keyword ‡πÄ‡∏û‡∏∑‡πà‡∏≠‡πÄ‡∏•‡∏∑‡∏≠‡∏Å Affiliation (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma): radiomics, radiomic, radiology, radiation, radiological \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "keywords = [k.strip() for k in user_input.split(\",\")]\n",
        "\n",
        "# Create regex pattern:\n",
        "# - Use re.escape to avoid issues with special characters\n",
        "# - Add '.*' after the keyword to allow partial matches (e.g., \"maxillo\" -> \"maxillofacial\")\n",
        "# - Use optional plural with s? but keep it flexible\n",
        "pattern_list = [f\"{re.escape(k)}.*\" for k in keywords]\n",
        "print(pattern_list)\n",
        "pattern = \"|\".join(pattern_list)\n",
        "\n",
        "# Filter DataFrame (case-insensitive)\n",
        "df_affiliation_filtered = df_default[\n",
        "    df_default['Affiliation'].str.contains(pattern, flags=re.IGNORECASE, na=False)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Display results\n",
        "print(df_affiliation_filtered.head())\n",
        "print(\"Total rows after filtering:\", len(df_affiliation_filtered))\n",
        "\n",
        "#orthodontic, odonto, maxillo,dental, oral, dentistry, perio, dento, prosthodontic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vjQNFeZpMlR0",
        "outputId": "3a822efd-cbac-44d5-a683-01d31139d8a4",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['radiomics.*', 'radiomic.*', 'radiology.*', 'radiation.*', 'radiological.*']\n",
            "       Name                               EMail  \\\n",
            "0  Witschey     witschey@pennmedicine.upenn.edu   \n",
            "1      Rusu      mihageorgeta@elearn.umfcluj.ro   \n",
            "2  Gunasena  rivindi.gunasena@health.qld.gov.au   \n",
            "3  Holtzman              holtzman.adam@mayo.edu   \n",
            "4       Woo                  wokhee@korea.ac.kr   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  The Role of an MRI-Based Radiomic Signature in...   \n",
            "2  A Pilot Study of PSMA PET/CT and MRI Fusion fo...   \n",
            "3  Heavy Ion Particle Therapy in Modern Day Radia...   \n",
            "4  MRI-based Radiomics for Ductal Carcinoma in Si...   \n",
            "\n",
            "                                         Affiliation     Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...                usa  \n",
            "1  Georgeta Mihaela Rusu (author), Department of ...            romania  \n",
            "2  Rivindi Gunasena (author), Department of Radio...          australia  \n",
            "3  Adam L. Holtzman (author), Department of Radia...                usa  \n",
            "4  Ok Hee Woo (author), Department of Radiology, ...  republic of korea  \n",
            "Total rows after filtering: 2757\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ùó# (optional) Generate file ‡∏ó‡∏µ‡πà specific keyword ‡πÉ‡∏ô affiliation # if you still do not want to get the file, it is no need to run"
      ],
      "metadata": {
        "id": "_KoI3fV9KKyI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
        "output_file = \"filtered_affiliation.xlsx\"\n",
        "\n",
        "# Export ‡πÄ‡∏õ‡πá‡∏ô Excel\n",
        "df_affiliation_filtered.to_excel(output_file, index=False)\n",
        "\n",
        "print(f\"Exported {len(df_affiliation_filtered)} rows to {output_file}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jpHHrxooQGC0",
        "outputId": "cde549fe-e8fa-439d-abce-ed1d9c6fd103"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Exported 1265 rows to filtered_affiliation.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(df_affiliation_filtered)"
      ],
      "metadata": {
        "id": "iQ-qmCO56pi6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4b51c563-a06b-485f-fd44-d2f18204849b",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Name                                EMail  \\\n",
            "0          Marciani          marciani.raffaele@gmail.com   \n",
            "1              K√ºhn               praxis@nicola-planz.de   \n",
            "2         Galluccio                    gabgall@gmail.com   \n",
            "3     Siotto-Pintor               alexsiotto77@gmail.com   \n",
            "4             Carmo       marianaisidrodocarmo@gmail.com   \n",
            "...             ...                                  ...   \n",
            "1539       Miyagawa  miyagawa.kazuaki.dent@osaka-u.ac.jp   \n",
            "1540        Takaoka     takaoka.ryota.dent@osaka-u.ac.jp   \n",
            "1541        Poolsin                w.s.poolsin@gmail.com   \n",
            "1542            Lee                    yejiali@gmail.com   \n",
            "1543          Ozaki                   ozakihry@gmail.com   \n",
            "\n",
            "                                              Reference  \\\n",
            "0     Towards Sustainable Orthodontics: Environmenta...   \n",
            "1     A Newly Developed Orthodontic-Logopedic Screen...   \n",
            "2     Treatment of Orthognathic Surgical Class III P...   \n",
            "3     Photodynamic Therapy in the Management of MDR ...   \n",
            "4     The Effects of Activated Carbon Toothpastes on...   \n",
            "...                                                 ...   \n",
            "1539  Association between the timing of secondary al...   \n",
            "1540  Changes in occlusal relationships observed usi...   \n",
            "1541  Impact of Vertical Facial Patterns on Three-Di...   \n",
            "1542  The surgical outcomes of anterior segmental os...   \n",
            "1543  Three-Dimensional Finite Element Analysis of E...   \n",
            "\n",
            "                                            Affiliation Country/Region  \n",
            "0     Raffaele Marciani (author), Department of Inno...          italy  \n",
            "1     Nicola K√ºhn (author), Praxis of Orthodontics N...        germany  \n",
            "2     Gabriella Galluccio (author), Department of Or...          italy  \n",
            "3     Alessandra Siotto-Pintor (author), Oral Biotec...          italy  \n",
            "4     Mariana Isidro Do Carmo (author), Department o...       portugal  \n",
            "...                                                 ...            ...  \n",
            "1539  Kazuaki Miyagawa (author), Department of Oral ...          japan  \n",
            "1540  Ryota Takaoka (author), Department of Fixed Pr...          japan  \n",
            "1541  Wasuthorn Poolsin (author), Graduate institute...         taiwan  \n",
            "1542  Yeji Lee (author), Department of Orthodontics,...    south korea  \n",
            "1543  Hiroya Ozaki (author), Division of Orthodontic...          japan  \n",
            "\n",
            "[1544 rows x 5 columns]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ù§ 3.) **Reference filtering - keep only specific row that match to the input**"
      ],
      "metadata": {
        "id": "01V8vRiHg6kx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏£‡∏±‡∏ö input keyword ‡∏à‡∏≤‡∏Å‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma)\n",
        "reference_input = input(\"‡∏Å‡∏£‡∏≠‡∏Å keyword in Reference (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma): \")"
      ],
      "metadata": {
        "id": "rjUd9G0Tg5Ka",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f821f6c8-01fd-4268-9919-00ffaf0cc953"
      },
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "‡∏Å‡∏£‡∏≠‡∏Å keyword in Reference (‡∏Ñ‡∏±‡πà‡∏ô‡∏î‡πâ‡∏ß‡∏¢ comma): radiomics, medical imaging, radiology, radiation therapy, radiation oncology, CT scan, PET/CT, Computed Tomography, MRI, Multimodal radiomics, Delta-radiomics, Feature Extraction, Magnetic Resonance Imaging, Positron Emission Tomography, Ultrasound, Multi-modality imaging, Quantitative imaging,Medical image, radiological , Texture analysis, Imaging biomarkers, Feature extraction, Radiogenomic, Artificial intelligence in medical imaging\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_ref = [k.strip() for k in reference_input.split(\",\")]\n",
        "\n",
        "# Create regex pattern:\n",
        "# - Use re.escape to avoid issues with special characters\n",
        "# - Add '.*' after the keyword to allow partial matches (e.g., \"maxillo\" -> \"maxillofacial\")\n",
        "# - Use optional plural with s? but keep it flexible\n",
        "pattern_list_ref = [f\"{re.escape(k)}.*\" for k in keywords_ref]\n",
        "print(pattern_list_ref)\n",
        "pattern_ref = \"|\".join(pattern_list_ref)\n",
        "\n",
        "# Filter DataFrame (case-insensitive)\n",
        "df_ref_filtered = df_default[\n",
        "    df_default['Reference'].str.contains(pattern_ref, flags=re.IGNORECASE, na=False)\n",
        "].reset_index(drop=True)\n",
        "\n",
        "# Display results\n",
        "print(df_ref_filtered.head())\n",
        "print(\"Total rows after filtering:\", len(df_ref_filtered))\n",
        "\n",
        "#orthodontic, odonto, maxillo,dental, oral, dentistry, perio, dento, prosthodontic"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "Tgvi0HEJisXC",
        "outputId": "84412014-f827-435f-d13b-ea430ec94c52"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['radiomics.*', 'medical\\\\ imaging.*', 'radiology.*', 'radiation\\\\ therapy.*', 'radiation\\\\ oncology.*', 'CT\\\\ scan.*', 'PET/CT.*', 'Computed\\\\ Tomography.*', 'MRI.*', 'Multimodal\\\\ radiomics.*', 'Delta\\\\-radiomics.*', 'Feature\\\\ Extraction.*', 'Magnetic\\\\ Resonance\\\\ Imaging.*', 'Positron\\\\ Emission\\\\ Tomography.*', 'Ultrasound.*', 'Multi\\\\-modality\\\\ imaging.*', 'Quantitative\\\\ imaging.*', 'Medical\\\\ image.*', 'radiological.*', 'Texture\\\\ analysis.*', 'Imaging\\\\ biomarkers.*', 'Feature\\\\ extraction.*', 'Radiogenomic.*', 'Artificial\\\\ intelligence\\\\ in\\\\ medical\\\\ imaging.*']\n",
            "       Name                            EMail  \\\n",
            "0  Witschey  witschey@pennmedicine.upenn.edu   \n",
            "1  Al Sayed          assemalsayed9@gmail.com   \n",
            "2    Kaseda      ryoheik@med.niigata-u.ac.jp   \n",
            "3      Rusu   mihageorgeta@elearn.umfcluj.ro   \n",
            "4       Oda           moda@is.nagoya-u.ac.jp   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  Radiological examination of greater palatine c...   \n",
            "2  Sodium Magnetic Resonance Imaging Shows Impair...   \n",
            "3  The Role of an MRI-Based Radiomic Signature in...   \n",
            "4  Automated Detection and Diagnosis of Spinal Sc...   \n",
            "\n",
            "                                         Affiliation Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...            usa  \n",
            "1  Assem Al Sayed (author), College of Osteopathi...            usa  \n",
            "2  Ryohei Kaseda (author), Division of Clinical N...          japan  \n",
            "3  Georgeta Mihaela Rusu (author), Department of ...        romania  \n",
            "4  Masahiro Oda (author), Information Strategy Of...          japan  \n",
            "Total rows after filtering: 9440\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚ùó# (optional) Generate file ‡∏ó‡∏µ‡πà specific keyword ‡πÉ‡∏ô reference # if you still do not want to get the file, it is no need to run"
      ],
      "metadata": {
        "id": "_NIpBqZwjf6Z"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
        "output_file_ref = \"filtered_ref.xlsx\"\n",
        "\n",
        "# Export ‡πÄ‡∏õ‡πá‡∏ô Excel\n",
        "df_ref_filtered.to_excel(output_file_ref, index=False)\n",
        "\n",
        "print(f\"Exported {len(df_ref_filtered)} rows to {output_file_ref}\")"
      ],
      "metadata": {
        "id": "y0h9jRgXji6Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ‚õ≥4) Keep only rows that shares between Filtered Affiliation Datafrom Reference Dataframe **"
      ],
      "metadata": {
        "id": "-GvQG0oNltP-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "specific_df_ref_aff=pd.merge(df_affiliation_filtered, df_ref_filtered, how='inner')"
      ],
      "metadata": {
        "id": "sYNJYF1AmV3o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(specific_df_ref_aff.head())\n",
        "print(len(specific_df_ref_aff))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k32ddanOmm0T",
        "outputId": "c9d1750d-9fb4-4584-c653-cabc6549bdc3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       Name                               EMail  \\\n",
            "0  Witschey     witschey@pennmedicine.upenn.edu   \n",
            "1      Rusu      mihageorgeta@elearn.umfcluj.ro   \n",
            "2  Gunasena  rivindi.gunasena@health.qld.gov.au   \n",
            "3  Holtzman              holtzman.adam@mayo.edu   \n",
            "4       Woo                  wokhee@korea.ac.kr   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  The Role of an MRI-Based Radiomic Signature in...   \n",
            "2  A Pilot Study of PSMA PET/CT and MRI Fusion fo...   \n",
            "3  Heavy Ion Particle Therapy in Modern Day Radia...   \n",
            "4  MRI-based Radiomics for Ductal Carcinoma in Si...   \n",
            "\n",
            "                                         Affiliation     Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...                usa  \n",
            "1  Georgeta Mihaela Rusu (author), Department of ...            romania  \n",
            "2  Rivindi Gunasena (author), Department of Radio...          australia  \n",
            "3  Adam L. Holtzman (author), Department of Radia...                usa  \n",
            "4  Ok Hee Woo (author), Department of Radiology, ...  republic of korea  \n",
            "2724\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 5) Generate final file to export"
      ],
      "metadata": {
        "id": "_pUK_i3UogVN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
        "# Ask user for file name\n",
        "final_file_name = input(\"Enter the name for the Excel file (without extension): \").strip()\n",
        "\n",
        "# Ensure the file name ends with .xlsx\n",
        "if not final_file_name.endswith(\".xlsx\"):\n",
        "    final_file_name = final_file_name + \".xlsx\"\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "specific_df_ref_aff.to_excel(final_file_name, index=False)\n",
        "\n",
        "print(f\"File saved as: {final_file_name}\")\n",
        "# Export ‡πÄ‡∏õ‡πá‡∏ô Excel\n",
        "specific_df_ref_aff.to_excel(final_file_name, index=False)\n",
        "\n",
        "print(f\"Exported {len(specific_df_ref_aff)} rows to {final_file_name}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12TCsLnGnQ9h",
        "outputId": "022cab81-a03f-48ed-872f-cadb90c2fd60"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter the name for the Excel file (without extension): CFP-scilit-2.9-processed\n",
            "File saved as: CFP-scilit-2.9-processed.xlsx\n",
            "Exported 2724 rows to CFP-scilit-2.9-processed.xlsx\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## (Optional)# **Concatenate 2 dataframes from Reference and Affiliation (Merge 2 dataframes) that contains specific keywords of both Reference and Affiliation**"
      ],
      "metadata": {
        "id": "Dme1v20fk4fG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "merged_ref_aff = pd.concat([df_affiliation_filtered, df_ref_filtered]).drop_duplicates().reset_index(drop=True)"
      ],
      "metadata": {
        "id": "pVd5Z-w4k3z8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(merged_ref_aff.head())\n",
        "print(len(merged_ref_aff ))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eum88Ndplazo",
        "outputId": "25ce1ec0-e2a4-4072-fc0d-d778f276d814",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "               Name                               EMail  \\\n",
            "0          Marciani         marciani.raffaele@gmail.com   \n",
            "1              K√ºhn              praxis@nicola-planz.de   \n",
            "2         Galluccio                   gabgall@gmail.com   \n",
            "3     Siotto-Pintor              alexsiotto77@gmail.com   \n",
            "4             Carmo      marianaisidrodocarmo@gmail.com   \n",
            "...             ...                                 ...   \n",
            "2532        Pieroni              mi.pieroni@uniroma1.it   \n",
            "2533        Fragola          martinafragola@gaslini.org   \n",
            "2534          Zhang               mia.zhangyf@gmail.com   \n",
            "2535     Haghshenas  elaheh.haghshenas@bison.howard.edu   \n",
            "2536           Nash             linton@nashortho.com.au   \n",
            "\n",
            "                                              Reference  \\\n",
            "0     Towards Sustainable Orthodontics: Environmenta...   \n",
            "1     A Newly Developed Orthodontic-Logopedic Screen...   \n",
            "2     Treatment of Orthognathic Surgical Class III P...   \n",
            "3     Photodynamic Therapy in the Management of MDR ...   \n",
            "4     The Effects of Activated Carbon Toothpastes on...   \n",
            "...                                                 ...   \n",
            "2532  Epigenetic Signatures of Dental Stem Cells: In...   \n",
            "2533  Parental Perceptions and Actual Oral Health St...   \n",
            "2534  Interdisciplinary management of an adolescent ...   \n",
            "2535  Effect of Interdental Enamel Reduction on Clin...   \n",
            "2536  A novel methodology for assessing, evaluating,...   \n",
            "\n",
            "                                            Affiliation Country/Region  \n",
            "0     Raffaele Marciani (author), Department of Inno...          italy  \n",
            "1     Nicola K√ºhn (author), Praxis of Orthodontics N...        germany  \n",
            "2     Gabriella Galluccio (author), Department of Or...          italy  \n",
            "3     Alessandra Siotto-Pintor (author), Oral Biotec...          italy  \n",
            "4     Mariana Isidro Do Carmo (author), Department o...       portugal  \n",
            "...                                                 ...            ...  \n",
            "2532  Michele Pieroni (author), Department of Bioche...          italy  \n",
            "2533  Martina Fragola (author), Biostatistics Unit, ...          italy  \n",
            "2534  Y Zhang (author), Private Practice Sydney Aust...      australia  \n",
            "2535  Elaheh Shafiei Haghshenas (author), Howard Uni...            usa  \n",
            "2536  Linton J. Nash (author), Senior Orthodontist, ...      australia  \n",
            "\n",
            "[2537 rows x 5 columns]\n",
            "2537\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# ‡∏Å‡∏≥‡∏´‡∏ô‡∏î path ‡πÅ‡∏•‡∏∞‡∏ä‡∏∑‡πà‡∏≠‡πÑ‡∏ü‡∏•‡πå‡∏ó‡∏µ‡πà‡∏ï‡πâ‡∏≠‡∏á‡∏Å‡∏≤‡∏£‡∏ö‡∏±‡∏ô‡∏ó‡∏∂‡∏Å\n",
        "# Ask user for file name\n",
        "final_file_name2 = input(\"Enter the name for the Excel file (without extension): \").strip()\n",
        "\n",
        "# Ensure the file name ends with .xlsx\n",
        "if not final_file_name2.endswith(\".xlsx\"):\n",
        "    final_file_name2 = final_file_name2 + \".xlsx\"\n",
        "\n",
        "# Save DataFrame to Excel\n",
        "merged_ref_aff.to_excel(final_file_name2, index=False)\n",
        "\n",
        "print(f\"File saved as: {final_file_name2}\")\n",
        "# Export ‡πÄ‡∏õ‡πá‡∏ô Excel\n",
        "merged_ref_aff.to_excel(final_file_name2, index=False)\n",
        "\n",
        "print(f\"Exported {len(merged_ref_aff)} rows to {final_file_name2}\")"
      ],
      "metadata": {
        "id": "6tkiFYVDp6FG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 6)  ********* From now you will get the file to export and upload in in-house system (Finder2, MRS-Editor invited) to find H-index of the scholars, IMPORT NEW FILE FROM IN-HOUSE SYSTEM AGAIN************"
      ],
      "metadata": {
        "id": "-bRBARKnr0S_"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï‚òï"
      ],
      "metadata": {
        "id": "q7HK1pTWwYqV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# --- Ask for file path of  filtered file [share specific keyword- Aff&Ref] ---\n",
        "file_aff = input(\"Enter path for filtered file [share specific keyword- Aff&Ref]: \").strip()\n",
        "specific_df_ref_aff_ = pd.read_excel(file_aff)\n",
        "\n",
        "print(\"‚úÖ File loaded successfully!\")\n",
        "print(specific_df_ref_aff_.head())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TlB0xE9tdE1P",
        "outputId": "b7d77bb7-2654-48c1-f64a-786391e1f980"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path for filtered file [share specific keyword- Aff&Ref]: /content/CFP-scilit-2.9-processed.xlsx\n",
            "‚úÖ File loaded successfully!\n",
            "       Name                               EMail  \\\n",
            "0  Witschey     witschey@pennmedicine.upenn.edu   \n",
            "1      Rusu      mihageorgeta@elearn.umfcluj.ro   \n",
            "2  Gunasena  rivindi.gunasena@health.qld.gov.au   \n",
            "3  Holtzman              holtzman.adam@mayo.edu   \n",
            "4       Woo                  wokhee@korea.ac.kr   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  The Role of an MRI-Based Radiomic Signature in...   \n",
            "2  A Pilot Study of PSMA PET/CT and MRI Fusion fo...   \n",
            "3  Heavy Ion Particle Therapy in Modern Day Radia...   \n",
            "4  MRI-based Radiomics for Ductal Carcinoma in Si...   \n",
            "\n",
            "                                         Affiliation     Country/Region  \n",
            "0  Walter R. Witschey (author), Department of Rad...                usa  \n",
            "1  Georgeta Mihaela Rusu (author), Department of ...            romania  \n",
            "2  Rivindi Gunasena (author), Department of Radio...          australia  \n",
            "3  Adam L. Holtzman (author), Department of Radia...                usa  \n",
            "4  Ok Hee Woo (author), Department of Radiology, ...  republic of korea  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "def clean_hindex(series):\n",
        "    \"\"\"\n",
        "    Convert H-index column to numeric:\n",
        "    - Non-numeric ‚Üí 0\n",
        "    - Blank/NaN ‚Üí 0\n",
        "    \"\"\"\n",
        "    return pd.to_numeric(series, errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# --- Step 1: Load and process Finder2 + MRS files ---\n",
        "file1 = input(\"Enter path for file from Finder2 (e.g. /content/Finder2.xlsx): \").strip()\n",
        "file2 = input(\"Enter path for file from MRS-editor-invited (e.g. /content/MRS-editor-invited.xlsx): \").strip()\n",
        "\n",
        "df1 = pd.read_excel(file1)\n",
        "df2 = pd.read_excel(file2)\n",
        "\n",
        "# Standardize column names\n",
        "df1 = df1.rename(columns={\"email\": \"Email\", \"h_index\": \"H-index\"})\n",
        "df2 = df2.rename(columns={\"email\": \"Email\", \"h_index\": \"H-index\"})\n",
        "\n",
        "# Clean H-index\n",
        "df1['H-index'] = clean_hindex(df1['H-index'])\n",
        "df2['H-index'] = clean_hindex(df2['H-index'])\n",
        "\n",
        "# Merge and keep max H-index\n",
        "merged = pd.merge(df1[['Email', 'H-index']],\n",
        "                  df2[['Email', 'H-index']],\n",
        "                  on='Email', suffixes=('_Finder2', '_MRS'))\n",
        "merged['H-index'] = merged[['H-index_Finder2', 'H-index_MRS']].max(axis=1)\n",
        "\n",
        "# Final result\n",
        "result = merged[['Email', 'H-index']]\n",
        "\n",
        "# --- Step 2: Merge with specific_df_ref_aff ---\n",
        "# (assumes you already loaded specific_df_ref_aff)\n",
        "merged_final = specific_df_ref_aff.merge(\n",
        "    result,\n",
        "    left_on=\"EMail\",\n",
        "    right_on=\"Email\",\n",
        "    how=\"left\"\n",
        ").drop(columns=[\"Email\"])\n",
        "\n",
        "# Ensure numeric\n",
        "merged_final['H-index'] = pd.to_numeric(merged_final['H-index'], errors='coerce').fillna(0).astype(int)\n",
        "\n",
        "# Reorder columns: put H-index after Country/Region\n",
        "col_order = ['Name', 'EMail', 'Reference', 'Affiliation', 'Country/Region', 'H-index']\n",
        "for col in merged_final.columns:\n",
        "    if col not in col_order:\n",
        "        col_order.append(col)\n",
        "merged_final = merged_final[col_order]\n",
        "\n",
        "# Discount rules\n",
        "def calc_discount(h):\n",
        "    if h <= 1:\n",
        "        return 0\n",
        "    elif 2 <= h <= 4:\n",
        "        return 20\n",
        "    elif 5 <= h <= 14:\n",
        "        return 50\n",
        "    else:\n",
        "        return 100\n",
        "\n",
        "# Insert discount column right after H-index\n",
        "merged_final.insert(\n",
        "    merged_final.columns.get_loc(\"H-index\") + 1,\n",
        "    \"discount (%)\",\n",
        "    merged_final[\"H-index\"].apply(calc_discount)\n",
        ")\n",
        "\n",
        "print(\"‚úÖ Done! New dataframe with H-index and discount added:\")\n",
        "print(merged_final.head())\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eLpshthdcR8O",
        "outputId": "7d9a6ccc-e6f9-4bac-9e6f-cb8bba2050a7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Enter path for file from Finder2 (e.g. /content/Finder2.xlsx): /content/Finder2-h-index-checked-2.9.xlsx\n",
            "Enter path for file from MRS-editor-invited (e.g. /content/MRS-editor-invited.xlsx): /content/MRS-h-index-checked-2.9.xlsx\n",
            "‚úÖ Done! New dataframe with H-index and discount added:\n",
            "       Name                               EMail  \\\n",
            "0  Witschey     witschey@pennmedicine.upenn.edu   \n",
            "1      Rusu      mihageorgeta@elearn.umfcluj.ro   \n",
            "2  Gunasena  rivindi.gunasena@health.qld.gov.au   \n",
            "3  Holtzman              holtzman.adam@mayo.edu   \n",
            "4       Woo                  wokhee@korea.ac.kr   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  The Role of an MRI-Based Radiomic Signature in...   \n",
            "2  A Pilot Study of PSMA PET/CT and MRI Fusion fo...   \n",
            "3  Heavy Ion Particle Therapy in Modern Day Radia...   \n",
            "4  MRI-based Radiomics for Ductal Carcinoma in Si...   \n",
            "\n",
            "                                         Affiliation     Country/Region  \\\n",
            "0  Walter R. Witschey (author), Department of Rad...                usa   \n",
            "1  Georgeta Mihaela Rusu (author), Department of ...            romania   \n",
            "2  Rivindi Gunasena (author), Department of Radio...          australia   \n",
            "3  Adam L. Holtzman (author), Department of Radia...                usa   \n",
            "4  Ok Hee Woo (author), Department of Radiology, ...  republic of korea   \n",
            "\n",
            "   H-index  discount (%)  \n",
            "0       22           100  \n",
            "1        1             0  \n",
            "2        0             0  \n",
            "3       10            50  \n",
            "4       24           100  \n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- Step 4: Save final output ---\n",
        "output_path = \"/content/filtered_CFP_list.xlsx\"\n",
        "merged_final.to_excel(output_path, index=False)\n",
        "\n",
        "print(\"‚úÖ Done! New dataframe with H-index and discount added.\")\n",
        "print(f\"üìÇ Output saved to: {output_path}\")\n",
        "print(merged_final.head())"
      ],
      "metadata": {
        "id": "cXlpbyGedeXN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f181ba2-2525-4229-9138-b61c537f9f75"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "‚úÖ Done! New dataframe with H-index and discount added.\n",
            "üìÇ Output saved to: /content/filtered_CFP_list.xlsx\n",
            "       Name                               EMail  \\\n",
            "0  Witschey     witschey@pennmedicine.upenn.edu   \n",
            "1      Rusu      mihageorgeta@elearn.umfcluj.ro   \n",
            "2  Gunasena  rivindi.gunasena@health.qld.gov.au   \n",
            "3  Holtzman              holtzman.adam@mayo.edu   \n",
            "4       Woo                  wokhee@korea.ac.kr   \n",
            "\n",
            "                                           Reference  \\\n",
            "0  Strategies for Implementing Machine Learning A...   \n",
            "1  The Role of an MRI-Based Radiomic Signature in...   \n",
            "2  A Pilot Study of PSMA PET/CT and MRI Fusion fo...   \n",
            "3  Heavy Ion Particle Therapy in Modern Day Radia...   \n",
            "4  MRI-based Radiomics for Ductal Carcinoma in Si...   \n",
            "\n",
            "                                         Affiliation     Country/Region  \\\n",
            "0  Walter R. Witschey (author), Department of Rad...                usa   \n",
            "1  Georgeta Mihaela Rusu (author), Department of ...            romania   \n",
            "2  Rivindi Gunasena (author), Department of Radio...          australia   \n",
            "3  Adam L. Holtzman (author), Department of Radia...                usa   \n",
            "4  Ok Hee Woo (author), Department of Radiology, ...  republic of korea   \n",
            "\n",
            "   H-index  discount (%)  \n",
            "0       22           100  \n",
            "1        1             0  \n",
            "2        0             0  \n",
            "3       10            50  \n",
            "4       24           100  \n"
          ]
        }
      ]
    }
  ]
}